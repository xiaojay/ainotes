{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60404c41-e6e4-4abc-9753-0d75093438b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "data_path = '../temp'\n",
    "c10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "c10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85265b49-ac70-46ba-9003-3e7e51b24bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "to_tensor = transforms.ToTensor()\n",
    "label_map = {0: 0, 2: 1}\n",
    "c2 = [(to_tensor(img), label_map[label])\n",
    "                 for img, label in c10\n",
    "                 if label in [0, 2]]\n",
    "c2_val = [(to_tensor(img), label_map[label])\n",
    "                 for img, label in c10_val\n",
    "                 if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca63fc2-2a8d-4768-8ede-79f679101274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab402ce-336f-45a0-8c9e-7a77f0ddaf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8*8*8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b559706-9034-42b9-9cd8-e89e86a4e9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = c2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2327a3ac-2222-42d2-b483-a4b3398d8196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a55b21-baa7-4f6d-8fb5-f5dbb4cf0275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4834d26-dbe9-4c0f-8b19-24b5ac2c3f51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0839, 0.1400]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b39a8f-97c1-42e3-9b88-a2fbd7cabfe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7d7749-0650-4856-9f2a-7c6ec8462276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = torch.stack([img[0].unsqueeze(0) for img in c2]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9ee2e5-0305-436b-8b9e-cec67e0541b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b563280b-1078-4735-b8cc-23cbdfd39a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5ea5037-d606-4bda-b8cd-d3b3a43907d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78196fa-2926-4838-b1fb-9398c9a55c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = torch.tensor([img[1] for img in c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ef8c855-7dc6-4d0d-982e-9eae1826e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f643fc5-9a84-4a18-af10-13845f94d75f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7061, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5568f702-bf06-4943-b57d-9a4620ea9f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5582008773935958"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.3 ** (-0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "779edd2e-20fe-44ea-8e02-55f40d692df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c520f8fc-fa39-4c07-9325-732fb7e4581c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4664, grad_fn=<NllLossBackward0>) 0.7965 0.8015\n",
      "5 tensor(0.4659, grad_fn=<NllLossBackward0>) 0.7967 0.803\n",
      "10 tensor(0.4655, grad_fn=<NllLossBackward0>) 0.7968 0.8025\n",
      "15 tensor(0.4651, grad_fn=<NllLossBackward0>) 0.7973 0.8025\n",
      "20 tensor(0.4647, grad_fn=<NllLossBackward0>) 0.7975 0.8025\n",
      "25 tensor(0.4643, grad_fn=<NllLossBackward0>) 0.7977 0.8025\n",
      "30 tensor(0.4638, grad_fn=<NllLossBackward0>) 0.7981 0.802\n",
      "35 tensor(0.4634, grad_fn=<NllLossBackward0>) 0.7984 0.802\n",
      "40 tensor(0.4630, grad_fn=<NllLossBackward0>) 0.798 0.802\n",
      "45 tensor(0.4626, grad_fn=<NllLossBackward0>) 0.798 0.8025\n",
      "50 tensor(0.4621, grad_fn=<NllLossBackward0>) 0.7981 0.802\n",
      "55 tensor(0.4617, grad_fn=<NllLossBackward0>) 0.7982 0.802\n",
      "60 tensor(0.4613, grad_fn=<NllLossBackward0>) 0.7982 0.803\n",
      "65 tensor(0.4609, grad_fn=<NllLossBackward0>) 0.7981 0.803\n",
      "70 tensor(0.4604, grad_fn=<NllLossBackward0>) 0.798 0.804\n",
      "75 tensor(0.4600, grad_fn=<NllLossBackward0>) 0.7981 0.8045\n",
      "80 tensor(0.4596, grad_fn=<NllLossBackward0>) 0.7987 0.8045\n",
      "85 tensor(0.4591, grad_fn=<NllLossBackward0>) 0.7989 0.804\n",
      "90 tensor(0.4587, grad_fn=<NllLossBackward0>) 0.7992 0.8045\n",
      "95 tensor(0.4582, grad_fn=<NllLossBackward0>) 0.7997 0.805\n",
      "100 tensor(0.4578, grad_fn=<NllLossBackward0>) 0.8001 0.805\n",
      "105 tensor(0.4574, grad_fn=<NllLossBackward0>) 0.8004 0.8055\n",
      "110 tensor(0.4569, grad_fn=<NllLossBackward0>) 0.8005 0.806\n",
      "115 tensor(0.4565, grad_fn=<NllLossBackward0>) 0.8012 0.806\n",
      "120 tensor(0.4560, grad_fn=<NllLossBackward0>) 0.8014 0.8065\n",
      "125 tensor(0.4556, grad_fn=<NllLossBackward0>) 0.8015 0.8065\n",
      "130 tensor(0.4552, grad_fn=<NllLossBackward0>) 0.8015 0.8065\n",
      "135 tensor(0.4547, grad_fn=<NllLossBackward0>) 0.8015 0.8065\n",
      "140 tensor(0.4543, grad_fn=<NllLossBackward0>) 0.8014 0.806\n",
      "145 tensor(0.4538, grad_fn=<NllLossBackward0>) 0.8017 0.8065\n",
      "150 tensor(0.4534, grad_fn=<NllLossBackward0>) 0.8019 0.8075\n",
      "155 tensor(0.4529, grad_fn=<NllLossBackward0>) 0.8019 0.8075\n",
      "160 tensor(0.4524, grad_fn=<NllLossBackward0>) 0.8021 0.8075\n",
      "165 tensor(0.4520, grad_fn=<NllLossBackward0>) 0.8024 0.8075\n",
      "170 tensor(0.4515, grad_fn=<NllLossBackward0>) 0.8028 0.8075\n",
      "175 tensor(0.4511, grad_fn=<NllLossBackward0>) 0.8029 0.807\n",
      "180 tensor(0.4506, grad_fn=<NllLossBackward0>) 0.803 0.808\n",
      "185 tensor(0.4501, grad_fn=<NllLossBackward0>) 0.8031 0.808\n",
      "190 tensor(0.4497, grad_fn=<NllLossBackward0>) 0.8032 0.808\n",
      "195 tensor(0.4492, grad_fn=<NllLossBackward0>) 0.8036 0.8085\n",
      "200 tensor(0.4488, grad_fn=<NllLossBackward0>) 0.8039 0.809\n",
      "205 tensor(0.4483, grad_fn=<NllLossBackward0>) 0.8039 0.8095\n",
      "210 tensor(0.4478, grad_fn=<NllLossBackward0>) 0.8041 0.8085\n",
      "215 tensor(0.4473, grad_fn=<NllLossBackward0>) 0.8044 0.809\n",
      "220 tensor(0.4469, grad_fn=<NllLossBackward0>) 0.8043 0.809\n",
      "225 tensor(0.4464, grad_fn=<NllLossBackward0>) 0.805 0.81\n",
      "230 tensor(0.4459, grad_fn=<NllLossBackward0>) 0.8051 0.8095\n",
      "235 tensor(0.4455, grad_fn=<NllLossBackward0>) 0.8057 0.81\n",
      "240 tensor(0.4450, grad_fn=<NllLossBackward0>) 0.8058 0.81\n",
      "245 tensor(0.4445, grad_fn=<NllLossBackward0>) 0.8056 0.8105\n",
      "250 tensor(0.4440, grad_fn=<NllLossBackward0>) 0.8056 0.81\n",
      "255 tensor(0.4435, grad_fn=<NllLossBackward0>) 0.8061 0.8105\n",
      "260 tensor(0.4431, grad_fn=<NllLossBackward0>) 0.8067 0.81\n",
      "265 tensor(0.4426, grad_fn=<NllLossBackward0>) 0.8065 0.8105\n",
      "270 tensor(0.4421, grad_fn=<NllLossBackward0>) 0.8066 0.811\n",
      "275 tensor(0.4416, grad_fn=<NllLossBackward0>) 0.8069 0.811\n",
      "280 tensor(0.4411, grad_fn=<NllLossBackward0>) 0.807 0.811\n",
      "285 tensor(0.4406, grad_fn=<NllLossBackward0>) 0.8072 0.811\n",
      "290 tensor(0.4402, grad_fn=<NllLossBackward0>) 0.807 0.8105\n",
      "295 tensor(0.4397, grad_fn=<NllLossBackward0>) 0.8075 0.8105\n",
      "300 tensor(0.4392, grad_fn=<NllLossBackward0>) 0.8076 0.8105\n",
      "305 tensor(0.4387, grad_fn=<NllLossBackward0>) 0.8079 0.81\n",
      "310 tensor(0.4382, grad_fn=<NllLossBackward0>) 0.8079 0.809\n",
      "315 tensor(0.4377, grad_fn=<NllLossBackward0>) 0.8084 0.81\n",
      "320 tensor(0.4372, grad_fn=<NllLossBackward0>) 0.8085 0.81\n",
      "325 tensor(0.4367, grad_fn=<NllLossBackward0>) 0.8091 0.81\n",
      "330 tensor(0.4362, grad_fn=<NllLossBackward0>) 0.8096 0.811\n",
      "335 tensor(0.4357, grad_fn=<NllLossBackward0>) 0.8095 0.8115\n",
      "340 tensor(0.4352, grad_fn=<NllLossBackward0>) 0.8098 0.8105\n",
      "345 tensor(0.4347, grad_fn=<NllLossBackward0>) 0.8103 0.8115\n",
      "350 tensor(0.4342, grad_fn=<NllLossBackward0>) 0.8106 0.812\n",
      "355 tensor(0.4337, grad_fn=<NllLossBackward0>) 0.811 0.812\n",
      "360 tensor(0.4332, grad_fn=<NllLossBackward0>) 0.8112 0.8125\n",
      "365 tensor(0.4327, grad_fn=<NllLossBackward0>) 0.8114 0.813\n",
      "370 tensor(0.4322, grad_fn=<NllLossBackward0>) 0.8116 0.8135\n",
      "375 tensor(0.4317, grad_fn=<NllLossBackward0>) 0.8122 0.8135\n",
      "380 tensor(0.4312, grad_fn=<NllLossBackward0>) 0.8121 0.813\n",
      "385 tensor(0.4307, grad_fn=<NllLossBackward0>) 0.8127 0.813\n",
      "390 tensor(0.4302, grad_fn=<NllLossBackward0>) 0.8128 0.813\n",
      "395 tensor(0.4297, grad_fn=<NllLossBackward0>) 0.8129 0.8135\n",
      "400 tensor(0.4292, grad_fn=<NllLossBackward0>) 0.8133 0.8135\n",
      "405 tensor(0.4287, grad_fn=<NllLossBackward0>) 0.8136 0.8135\n",
      "410 tensor(0.4282, grad_fn=<NllLossBackward0>) 0.8142 0.813\n",
      "415 tensor(0.4277, grad_fn=<NllLossBackward0>) 0.8142 0.813\n",
      "420 tensor(0.4272, grad_fn=<NllLossBackward0>) 0.8141 0.8125\n",
      "425 tensor(0.4267, grad_fn=<NllLossBackward0>) 0.8142 0.813\n",
      "430 tensor(0.4262, grad_fn=<NllLossBackward0>) 0.8144 0.8125\n",
      "435 tensor(0.4257, grad_fn=<NllLossBackward0>) 0.8145 0.813\n",
      "440 tensor(0.4252, grad_fn=<NllLossBackward0>) 0.8145 0.813\n",
      "445 tensor(0.4247, grad_fn=<NllLossBackward0>) 0.8148 0.813\n",
      "450 tensor(0.4242, grad_fn=<NllLossBackward0>) 0.8148 0.813\n",
      "455 tensor(0.4237, grad_fn=<NllLossBackward0>) 0.8145 0.8125\n",
      "460 tensor(0.4232, grad_fn=<NllLossBackward0>) 0.8146 0.8125\n",
      "465 tensor(0.4227, grad_fn=<NllLossBackward0>) 0.8148 0.8125\n",
      "470 tensor(0.4222, grad_fn=<NllLossBackward0>) 0.8149 0.8125\n",
      "475 tensor(0.4217, grad_fn=<NllLossBackward0>) 0.8153 0.8125\n",
      "480 tensor(0.4212, grad_fn=<NllLossBackward0>) 0.8153 0.8125\n",
      "485 tensor(0.4207, grad_fn=<NllLossBackward0>) 0.8156 0.813\n",
      "490 tensor(0.4202, grad_fn=<NllLossBackward0>) 0.8159 0.813\n",
      "495 tensor(0.4197, grad_fn=<NllLossBackward0>) 0.8159 0.813\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    outputs = model(imgs)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    trainer.zero_grad()\n",
    "    loss.backward()\n",
    "    trainer.step()\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        print(i, loss, evaluate_train(outputs), evaluate_val())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b737aee-7b4e-48da-832e-93b73de6bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = torch.tensor([img[1] for img in c2_val])\n",
    "imgs_val = torch.stack([img[0].unsqueeze(0) for img in c2_val]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84a6d9a1-f5ad-4ba2-be43-048137467f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_val():\n",
    "    pred = model(imgs_val)\n",
    "    _, p = torch.max(pred, dim=1)\n",
    "    return int((labels_val == p).sum())/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ceb62d-2180-427c-8810-ffc921f3948c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6965"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5238db7-5a7e-4a92-a2e3-4cd3f6f0b82d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_train(pred):\n",
    "    _, p = torch.max(pred, dim=1)\n",
    "    return int((labels == p).sum())/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecd188ed-689f-4885-9054-c961f3b2a7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6603923b-ed38-4df7-ac79-b79c2ca4f8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7423"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_train(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b60d9-6e94-460a-9c84-53654dad2452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
